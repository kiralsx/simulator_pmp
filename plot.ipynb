{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspace/simulator.v3/results/apollo/5_azure_2_dgx/workloads-test\n",
      "Processing /workspace/simulator.v3/results/gavel/5_azure_2_dgx/workloads-test\n",
      "{'cifar10': {'azure': 0.09166666666666666, 'dgx-ext': 0.4}, 'gpt-15b': {'dgx-ext': 51.599999999999994, 'azure': 56.83333333333333}, 'gpt-6.7b': {'dgx-ext': 15.133333333333333}}\n",
      "{'cifar10': {'dgx-ext': 0.8}, 'gpt-15b': {'azure': 274.4}, 'gpt-6.7b': {'azure': 0.4, 'dgx-ext': 15.2}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import job_name_map\n",
    "\n",
    "\"\"\" ######################## gpu hours ###################### \"\"\"\n",
    "def compute_gpu_hrs_model(logfile, interval=60, time_limit=-1):\n",
    "    gpu_usage = dict()\n",
    "    model_counts = dict()\n",
    "    jobnames = set()\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            logline = json.loads(line)\n",
    "            logtime = logline['timestamp']\n",
    "            if logtime > time_limit * 3600:\n",
    "                break\n",
    "            for job in logline['submitted_jobs']:\n",
    "                # job already finished or no allocation\n",
    "                if job['completion_time'] is not None or job['allocation'] is None:\n",
    "                    continue\n",
    "                \n",
    "                if job['real_job_name'] is None:\n",
    "                    model_name = job['name'].split('-')[0]\n",
    "                else:\n",
    "                    s = job['real_job_name'].split('-')\n",
    "                    model_name = s[0] + '-' + s[1]\n",
    "                if model_name not in gpu_usage:\n",
    "                    gpu_usage[model_name] = dict()\n",
    "                    model_counts[model_name] = 0\n",
    "\n",
    "                jobname_ = job['name'] if job['real_job_name'] is None else job['real_job_name']\n",
    "                if jobname_ not in jobnames:\n",
    "                    model_counts[model_name] += 1\n",
    "                    jobnames.add(jobname_)\n",
    "                    \n",
    "                assert len(job['allocation']) == 1\n",
    "                alloc_ = [(k, v) for k, v in job['allocation'].items()]\n",
    "                cluster, alloc = alloc_[0][0], alloc_[0][1]\n",
    "                \n",
    "                gpu_usage[model_name][cluster] = gpu_usage[model_name].get(\n",
    "                    cluster, 0) + len(alloc)\n",
    "    gpu_hrs = dict()\n",
    "    for model, gpu_units in gpu_usage.items():\n",
    "        gpu_hrs[model] = dict()\n",
    "        for cluster, sum_gpus in gpu_units.items():\n",
    "            gpu_hrs[model][cluster] = (\n",
    "                sum_gpus * interval / 3600) / model_counts[model]\n",
    "    return gpu_hrs\n",
    "\n",
    "\n",
    "def compute_gpu_hrs_model_dir(dir, time_limit, interval=60):\n",
    "    print(f\"Processing {dir}\")\n",
    "    gpu_hrs = dict()\n",
    "    count = 0\n",
    "    for logfile in glob.glob(dir + \"/workload*.log\"):\n",
    "        workload_occ = compute_gpu_hrs_model(logfile, interval, time_limit)\n",
    "        for model, occ in workload_occ.items():\n",
    "            if model not in gpu_hrs:\n",
    "                gpu_hrs[model] = dict()\n",
    "            for cluster, cluster_gpu_hrs in occ.items():\n",
    "                gpu_hrs[model][cluster] = gpu_hrs[model].get(\n",
    "                    cluster, 0) + cluster_gpu_hrs\n",
    "        count += 1\n",
    "\n",
    "    for model in gpu_hrs.keys():\n",
    "        for cluster in gpu_hrs[model].keys():\n",
    "            gpu_hrs[model][cluster] /= count\n",
    "\n",
    "    return gpu_hrs\n",
    "\n",
    "\n",
    "# haware_gpu_hrs = compute_gpu_hrs_model_dir(\"/logs/haware_mip/philly_b\", 48)\n",
    "# hunaware_gpu_hrs = compute_gpu_hrs_model_dir(\"/logs/unaware_weighted_mip/philly_b\", 48)\n",
    "# pollux_gpu_hrs = compute_gpu_hrs_model_dir(\"/logs/unaware_pollux/philly_b_run2\", 48)\n",
    "# gavel_gpu_hrs = compute_gpu_hrs_model_dir(\"/logs/gavel/philly_b\", interval=180, time_limit=48)\n",
    "haware_gpu_hrs = compute_gpu_hrs_model_dir(\"/workspace/simulator.v3/results/apollo/5_azure_2_dgx/workloads-test\", 48)\n",
    "gavel_gpu_hrs = compute_gpu_hrs_model_dir(\n",
    "    \"/workspace/simulator.v3/results/gavel/5_azure_2_dgx/workloads-test\", interval=180, time_limit=48)\n",
    "print(haware_gpu_hrs)\n",
    "print(gavel_gpu_hrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads\n",
      "['/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload8.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload3.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload7.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload1.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload2.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload4.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload6.log', '/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload5.log']\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload8.log\n",
      "{'cifar10': {'restart': 119.25, 'azure': 238.75, 'dgx-ext': 262.5}, 'yolov3': {'restart': 493.125, 'azure': 7571.25, 'dgx-ext': 830.625}, 'gpt-15b': {'restart': 213.75, 'azure': 12138.75, 'dgx-ext': 7732.5, 'suspend': 48195.0}, 'deepspeech2': {'restart': 168.52941176470588, 'dgx-ext': 325.5882352941176, 'azure': 2498.823529411765}, 'imagenet': {'restart': 805.0, 'dgx-ext': 6975.0, 'azure': 29220.0}, 'gpt-6.7b': {'restart': 120.0, 'dgx-ext': 22937.5, 'suspend': 3640.0, 'azure': 4832.5}, 'gpt-1.3b': {'restart': 405.0, 'dgx-ext': 915.0, 'azure': 11700.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload3.log\n",
      "{'cifar10': {'restart': 123.55932203389831, 'azure': 173.26271186440678, 'dgx-ext': 263.00847457627117}, 'deepspeech2': {'restart': 205.71428571428572, 'azure': 2428.9285714285716, 'dgx-ext': 288.2142857142857}, 'gpt-15b': {'restart': 234.0, 'dgx-ext': 8199.0, 'azure': 9615.0, 'suspend': 38832.0}, 'yolov3': {'restart': 420.0, 'dgx-ext': 523.9285714285714, 'azure': 7443.214285714285}, 'gpt-6.7b': {'restart': 210.0, 'dgx-ext': 19830.0, 'azure': 5580.0, 'suspend': 1870.0}, 'gpt-1.3b': {'restart': 690.0, 'dgx-ext': 825.0, 'azure': 7785.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload7.log\n",
      "{'cifar10': {'restart': 117.09677419354838, 'azure': 293.46774193548384, 'dgx-ext': 242.66129032258064}, 'gpt-15b': {'restart': 247.5, 'azure': 12285.0, 'dgx-ext': 7477.5, 'suspend': 58035.0}, 'deepspeech2': {'restart': 170.0, 'dgx-ext': 20.0, 'azure': 2970.0}, 'yolov3': {'restart': 339.0, 'dgx-ext': 520.5, 'azure': 7528.5}, 'imagenet': {'restart': 810.0, 'azure': 35511.0, 'dgx-ext': 10575.0}, 'gpt-6.7b': {'restart': 150.0, 'dgx-ext': 23760.0, 'azure': 4310.0, 'suspend': 4770.0}, 'gpt-1.3b': {'restart': 337.5, 'dgx-ext': 945.0, 'azure': 7267.5}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload1.log\n",
      "{'cifar10': {'restart': 129.96268656716418, 'azure': 73.32089552238806, 'dgx-ext': 292.8358208955224}, 'deepspeech2': {'restart': 203.75, 'azure': 2215.0, 'dgx-ext': 126.25}, 'imagenet': {'restart': 907.5, 'azure': 17951.25, 'dgx-ext': 14771.25}, 'gpt-15b': {'restart': 405.0, 'azure': 17895.0, 'dgx-ext': 4900.0, 'suspend': 28260.0}, 'yolov3': {'restart': 755.0, 'dgx-ext': 1595.0, 'azure': 6710.0}, 'gpt-6.7b': {'restart': 510.0, 'dgx-ext': 27680.0, 'azure': 770.0, 'suspend': 20.0}, 'gpt-1.3b': {'restart': 1305.0, 'dgx-ext': 2490.0, 'azure': 3645.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload2.log\n",
      "{'cifar10': {'restart': 127.13709677419355, 'azure': 118.66935483870968, 'dgx-ext': 323.2258064516129}, 'imagenet': {'restart': 1705.0, 'azure': 23915.0, 'dgx-ext': 11500.0}, 'yolov3': {'restart': 415.7142857142857, 'azure': 7613.571428571428, 'dgx-ext': 550.7142857142857}, 'gpt-15b': {'restart': 135.0, 'azure': 12470.0, 'suspend': 28920.0, 'dgx-ext': 8155.0}, 'deepspeech2': {'restart': 156.66666666666666, 'azure': 2965.8333333333335, 'dgx-ext': 44.166666666666664}, 'gpt-6.7b': {'restart': 180.0, 'dgx-ext': 22490.0, 'suspend': 520.0, 'azure': 1190.0}, 'gpt-1.3b': {'restart': 765.0, 'dgx-ext': 4335.0, 'azure': 4560.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload4.log\n",
      "{'gpt-15b': {'restart': 450.0, 'dgx-ext': 6320.0, 'azure': 13010.0, 'suspend': 36680.0}, 'cifar10': {'restart': 120.5813953488372, 'azure': 182.32558139534885, 'dgx-ext': 270.5813953488372}, 'deepspeech2': {'restart': 217.5, 'dgx-ext': 117.85714285714286, 'azure': 2437.5}, 'imagenet': {'restart': 1323.75, 'azure': 19192.5, 'dgx-ext': 14298.75}, 'yolov3': {'restart': 250.0, 'azure': 8045.0, 'dgx-ext': 65.0}, 'gpt-6.7b': {'restart': 345.0, 'dgx-ext': 24770.0, 'azure': 3385.0, 'suspend': 60.0}, 'gpt-1.3b': {'restart': 315.0, 'azure': 3645.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload6.log\n",
      "{'cifar10': {'restart': 120.0, 'azure': 369.0495867768595, 'dgx-ext': 184.83471074380165}, 'deepspeech2': {'restart': 176.25, 'azure': 2840.625, 'dgx-ext': 1.875}, 'gpt-15b': {'restart': 279.0, 'dgx-ext': 8187.0, 'azure': 11022.0, 'suspend': 51360.0}, 'gpt-6.7b': {'restart': 282.85714285714283, 'dgx-ext': 22677.85714285714, 'azure': 3696.4285714285716, 'suspend': 5948.571428571428}, 'imagenet': {'restart': 990.0, 'azure': 32990.0, 'dgx-ext': 7500.0}, 'yolov3': {'restart': 303.0, 'azure': 7992.0, 'dgx-ext': 9.0}, 'gpt-1.3b': {'restart': 525.0, 'dgx-ext': 295.0, 'azure': 8460.0}}\n",
      "/workspace/simulator.v3/results/apollo/5_azure_2_dgx/no_ncf_workloads/workload5.log\n",
      "{'cifar10': {'restart': 121.171875, 'azure': 216.9140625, 'dgx-ext': 256.7578125}, 'yolov3': {'restart': 527.5, 'azure': 7762.5, 'dgx-ext': 360.0}, 'gpt-15b': {'restart': 247.5, 'azure': 12045.0, 'dgx-ext': 7852.5, 'suspend': 42330.0}, 'imagenet': {'restart': 1267.5, 'dgx-ext': 7946.25, 'azure': 32216.25}, 'deepspeech2': {'restart': 163.63636363636363, 'azure': 2942.7272727272725, 'dgx-ext': 13.636363636363637}, 'gpt-6.7b': {'restart': 225.0, 'dgx-ext': 22938.0, 'azure': 3981.0, 'suspend': 1440.0}, 'gpt-1.3b': {'restart': 652.5, 'dgx-ext': 780.0, 'azure': 11767.5}}\n",
      "\n",
      "### gavel runtime\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gavel_runtime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_435074/2572822359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### gavel runtime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgavel_runtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gavel_runtime' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import job_name_map\n",
    "\"\"\" ######################## run time details ###################### \"\"\"\n",
    "\n",
    "def compute_runtime(logfile, interval=60, time_limit=-1):\n",
    "    runtime = dict()\n",
    "    model_counts = dict()\n",
    "    jobnames = set()\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            logline = json.loads(line)\n",
    "            logtime = logline['timestamp']\n",
    "            if logtime > time_limit * 3600:\n",
    "                break\n",
    "            for job in logline['submitted_jobs']:\n",
    "                # job already finished\n",
    "                if job['completion_time'] is not None:\n",
    "                    continue\n",
    "\n",
    "                if job['real_job_name'] is None:\n",
    "                    model_name = job['name'].split('-')[0]\n",
    "                else:\n",
    "                    s = job['real_job_name'].split('-')\n",
    "                    model_name = s[0] + '-' + s[1]\n",
    "                if model_name not in runtime:\n",
    "                    runtime[model_name] = dict()\n",
    "                    model_counts[model_name] = 0\n",
    "\n",
    "                jobname_ = job['name'] if job['real_job_name'] is None else job['real_job_name']\n",
    "                if jobname_ not in jobnames:\n",
    "                    model_counts[model_name] += 1\n",
    "                    jobnames.add(jobname_)\n",
    "\n",
    "                if job['allocation'] is None:  # no allocation\n",
    "                    status = 'suspend'\n",
    "                    runtime[model_name][status] = runtime[model_name].get(\n",
    "                        status, 0) + interval\n",
    "                else:\n",
    "                    if job['overhead'] != 0:  # use the last placement\n",
    "                        status = 'restart'\n",
    "                        runtime[model_name][status] = runtime[model_name].get(\n",
    "                            status, 0) + job['overhead']\n",
    "\n",
    "                    alloc_ = [(k, v) for k, v in job['allocation'].items()]\n",
    "                    assert len(alloc_) == 1\n",
    "                    cluster, alloc = alloc_[0][0], alloc_[0][1]\n",
    "                    status = cluster\n",
    "                    runtime[model_name][status] = runtime[model_name].get(\n",
    "                        status, 0) + interval - job['overhead']\n",
    "\n",
    "    res = {model: {status: time/model_counts[model] for status,\n",
    "                   time in status_time.items()} for model, status_time in runtime.items()}\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_runtime_dir(dir, time_limit, interval=60):\n",
    "    print(f\"Processing {dir}\")\n",
    "    res = dict()\n",
    "    count = 0\n",
    "    print(glob.glob(dir + \"/workload*.log\"))\n",
    "    for logfile in glob.glob(dir + \"/workload*.log\"):\n",
    "        print(logfile)\n",
    "        workload_occ = compute_runtime(logfile, interval, time_limit)\n",
    "        print(workload_occ)\n",
    "        for model, occ in workload_occ.items():\n",
    "            if model not in res:\n",
    "                res[model] = dict()\n",
    "            for status, time in occ.items():\n",
    "                res[model][status] = res[model].get(\n",
    "                    status, 0) + time\n",
    "        count += 1\n",
    "\n",
    "    for model in res.keys():\n",
    "        for status in res[model].keys():\n",
    "            res[model][status] /= count\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_normed(input_hrs, norm_hrs):\n",
    "    normed_model_hrs = dict()\n",
    "    for model, hrs in input_hrs.items():\n",
    "        normed_hrs = dict()\n",
    "        for cluster, hr in hrs.items():\n",
    "            normed_hrs[cluster] = hr / norm_hrs[model]\n",
    "        normed_model_hrs[model] = normed_hrs\n",
    "    return normed_model_hrs\n",
    "\n",
    "\n",
    "def get_points(nhrs):\n",
    "    points = []\n",
    "    for cluster in cluster_ordering:\n",
    "        cur_points = []\n",
    "        for model in model_ordering:\n",
    "            cur_points.append(nhrs[model].get(cluster, 0))\n",
    "        points.append(np.asarray(cur_points))\n",
    "    return points\n",
    "\n",
    "\n",
    "def plot_points(points, offset, display_str, cluster_names, cluster_colors):\n",
    "    cur_sum = np.zeros_like(points[0])\n",
    "    global label_added\n",
    "    for i, cur_points in enumerate(points):\n",
    "        print(cur_sum)\n",
    "        cluster = cluster_ordering[i]\n",
    "        label = cluster_names[cluster] if not label_added else None\n",
    "        b = plt.bar(Xs + offset, cur_points, label=label, color=cluster_colors[cluster],\n",
    "                    bottom=cur_sum, width=barwidth)\n",
    "        cur_sum += cur_points\n",
    "\n",
    "    for x, y in zip(Xs + offset - barwidth / 2 + 0.02, 0.05 + np.zeros_like(Xs)):\n",
    "        plt.gca().text(x, y, display_str, fontsize=12, fontweight='bold', color='w')\n",
    "    label_added = True\n",
    "\n",
    "cluster_spec = '5_azure_2_dgx'\n",
    "workloads = 'no_ncf_workloads'\n",
    "haware_runtime = compute_runtime_dir(\n",
    "    f\"/workspace/simulator.v3/results/apollo/{cluster_spec}/{workloads}\", 48)\n",
    "gavel_runtime = compute_runtime_dir(\n",
    "    f\"/workspace/simulator.v3/results/gavel/{cluster_spec}/{workloads}\", interval=180, time_limit=240)\n",
    "print(\"### apollo runtime\")\n",
    "print(haware_runtime)\n",
    "print('')\n",
    "print(\"### gavel runtime\")\n",
    "print(gavel_runtime)\n",
    "\n",
    "\n",
    "# normalize\n",
    "norm_runtime = dict()\n",
    "for model, allocs in haware_runtime.items():\n",
    "    norm_runtime[model] = sum(allocs.values())\n",
    "print('\\n### normalized runtime')\n",
    "print(norm_runtime)\n",
    "\n",
    "haware_runtime_norm = compute_normed(haware_runtime, norm_runtime)\n",
    "gavel_runtime_norm = compute_normed(gavel_runtime, norm_runtime)\n",
    "print('\\n### normalized gavel runtime')\n",
    "print(gavel_runtime_norm)\n",
    "\n",
    "\n",
    "points_ordering = [haware_runtime_norm]\n",
    "Xs = np.arange(len(haware_runtime_norm))\n",
    "model_ordering = list(haware_runtime_norm.keys())\n",
    "cluster_colors = {'restart': 'g', 'suspend': 'r', 'azure': 'b', 'dgx-ext': 'y'}\n",
    "cluster_names = {'restart': 'restart', 'suspend': 'suspend', 'azure': 'v100', 'dgx-ext': 'a100'}\n",
    "cluster_ordering = ['dgx-ext', 'azure', 'suspend', 'restart']\n",
    "\n",
    "haware_points = get_points(haware_runtime_norm)\n",
    "gavel_points = get_points(gavel_runtime_norm)\n",
    "\n",
    "plt.clf()\n",
    "label_added = False\n",
    "barwidth = 0.2\n",
    "\n",
    "offsets = [0, 0.25]\n",
    "plot_pts = [haware_points, gavel_points]\n",
    "display_strs = ['A', 'G']\n",
    "for plot_pt, offset, display_str in zip(plot_pts, offsets, display_strs):\n",
    "  plot_points(plot_pt, offset, display_str, cluster_names, cluster_colors)\n",
    "\n",
    "plt.axhline(y=1.0, color='k', linewidth=0.3, linestyle='--')\n",
    "for i in range(len(Xs) - 1):\n",
    "  plt.axvline(x=Xs[i] + 0.5, color='k', linewidth=1)\n",
    "plt.xticks(ticks=Xs, labels=[x for x in model_ordering], rotation=0, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gcf().set_size_inches(6, 2.25)\n",
    "plt.gcf().set_tight_layout(tight=1)\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.ylabel('JCT (hrs)', fontsize=12)\n",
    "plt.show()\n",
    "# plt.savefig('/tmp/norm_gpu_hrs.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
